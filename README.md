# hi ğŸ³

this is a minimal implementation of gpt-2 using jax. i was reading the attetnion is all you need paper and wanted to implement it myself. it's probably very slow and memory inefficient but it's still fun and under 100 lines of code.